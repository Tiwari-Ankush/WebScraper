{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TiwariBro/WebScraper/blob/main/Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "import urllib.request  # Module for handling URLs\n",
        "\n",
        "from bs4 import BeautifulSoup  # BeautifulSoup for HTML parsing\n",
        "\n",
        "import os  # Module for interacting with the operating system\n"
      ],
      "metadata": {
        "id": "YXqorjDERiPV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a class named Scraper\n",
        "class Scraper:\n",
        "\n",
        "    # Constructor method to initialize the object with a website URL\n",
        "    def __init__(self, site):\n",
        "\n",
        "        self.site = site  # Assign the provided website URL\n",
        "\n",
        "        # Default output file name\n",
        "        self.output_file = \"output.txt\"\n",
        "\n",
        "    # Method to perform web scraping\n",
        "    def scrape(self):\n",
        "\n",
        "        # Open a connection to the website\n",
        "        r = urllib.request.urlopen(self.site)\n",
        "\n",
        "        # Read the HTML content of the page\n",
        "        html = r.read()\n",
        "\n",
        "        # Specify the HTML parser\n",
        "        parser = \"html.parser\"\n",
        "\n",
        "        # Create a BeautifulSoup object to parse the HTML\n",
        "        sp = BeautifulSoup(html, parser)\n",
        "\n",
        "        # Check if the output file already exists\n",
        "        if os.path.exists(self.output_file):\n",
        "\n",
        "            # If it exists, find the next available file name\n",
        "            index = 1\n",
        "            while os.path.exists(f\"output({index}).txt\"):\n",
        "                index += 1\n",
        "\n",
        "            # Update the output file name\n",
        "            self.output_file = f\"output({index}).txt\"\n",
        "\n",
        "        # Open the output file in write mode\n",
        "        with open(self.output_file, \"w\") as file:\n",
        "\n",
        "            # Loop through all <a> tags in the HTML\n",
        "            for tag in sp.find_all(\"a\"):\n",
        "\n",
        "                # Get the \"href\" attribute of the <a> tag\n",
        "                url = tag.get(\"href\")\n",
        "\n",
        "                # Skip if the URL is None\n",
        "                if url is None:\n",
        "                    continue\n",
        "\n",
        "                # Write the URL to the output file if it contains \"articles\"\n",
        "                if \"articles\" in url:\n",
        "                    file.write(url + \"\\n\")\n",
        "\n",
        "# Example usage\n",
        "# Define the website URL\n",
        "news = \"https://news.google.com/\"\n",
        "\n",
        "# Create a Scraper object and perform scraping\n",
        "Scraper(news).scrape()"
      ],
      "metadata": {
        "id": "KXfEmk_tRo7f"
      },
      "execution_count": 45,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPyux1rEO981wqoWGo7kts",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}